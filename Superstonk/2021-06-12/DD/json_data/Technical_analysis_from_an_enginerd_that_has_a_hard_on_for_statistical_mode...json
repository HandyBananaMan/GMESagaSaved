{
    "author": "PWNWTFBBQ",
    "created_utc": 1623502937.0,
    "distinguished": null,
    "edited": 1626035621.0,
    "id": "ny68t6",
    "text_only": true,
    "flair_text": "DD \ud83d\udc68\u200d\ud83d\udd2c",
    "name": "t3_ny68t6",
    "num_comments": 187,
    "permalink": "/r/Superstonk/comments/ny68t6/technical_analysis_from_an_enginerd_that_has_a/",
    "score": 1819,
    "selftext": "# Debunked: Incorrect Assumptions\n\nThe below data analysis has been determined to be not accurate due to GME trend to not follow a single linear line that fits perfectly by date. I tried to apply the exponential floor theory and make it work but was unable to do so.\n\n# Post\n\nI am not a financial advisor. I am merely a fucking autistic number crunching, experiment running engineer. This is my view point.\n\nWith all the various technical analysis people chiming in, I figured I would provide my thoughts from an engineering statistics view. Engineering stats is different from financial stats because we are more focused on the data as a whole and only concerned with outliers when there are a shit ton of outliers. This is an over generalization but I\u2019m giving a quick explanation on how this approach is different from the rest. I also only used log ape\u2019s data since the EW, sideways trading, and gamma apes use a financial analysis technique that is too financial analysis-y and not pure mathemagically.\n\nI\u2019m not bothered by how the last few data points were below the log equation and here\u2019s a few reasons why:\n\n1. Outliers are common in any distribution.\n2. Data points usually deviate from a trend due to some form of bias.\n\n**Outliers are common in multivariate regression.**\n\nFor the sake of easier understanding, I am only going to address the normal bell curve distributions. There are two important statistical values to this type of distribution. The first is the average / mean represented by \u03bc. The other is the standard deviation represented by \u03c3.\n\nFor a given data set that has a normal distribution, 68% of the data will fall within +/- 1 \u03c3. 95% of the data will between +/- 2 \u03c3. Finally 99.7% will fall within +/- 3 \u03c3. This is called the 68 - 95 - 99.7 rule in stats.\n\n&#x200B;\n\n[I'm so pretty, I model.... statistical model.](https://preview.redd.it/i00678hl0u471.png?width=500&format=png&auto=webp&s=e3209c34f950dd5685c044a2220bcc13ab078d5f)\n\nSo, if you know the distribution of a data set, you\u2019ll know what percentile a single data point will fall into in comparison to the rest of the data. Percentiles are great because they can also act as probabilities. Here is an ape level example to show how:\n\nLet\u2019s say we have a group of 100 crayons all with different lengths. For this particular group of crayons, the average length of a single crayon is 10 cm, and the standard deviation is 1 cm. That means 68% of the crayons are going to be 9 - 11 cm. 95% of the crayons will be 8 - 12 cm, and 99.7% of the crayons are going to be 7 to 13 cm. It would create this type of distribution:\n\n&#x200B;\n\n[MMM crayons](https://preview.redd.it/eyllc4ipcu471.png?width=1792&format=png&auto=webp&s=5f5d8bfe8283a8ad024a4f6c312f67537bf62dee)\n\nHere is where the probability part comes in:\n\nLet\u2019s say you suddenly had a crayon that was 13 cm long which according to our graph is 3\u03c3 away from the average. Looking at the pretty graph, we can see that a 13 cm long crayon is bigger than 99.85% of the rest of the crayons. Where did the 99.85% come from? We counted all the crayons that were less than 13 cm to include anything below 7 cm:\n\n2.35 + 13.5 + 34 + 34 + 13.5 + 2.35 + 0.15 = 99.85%\n\nBut what the fuck? Where did that additional 0.15 come from when +/- 3\u03c3 is 99.7% It came from also counting in the number of crayons that are below 7 cm in length. Since probability cannot be greater than 100% and this is a symmetrical curve, 0.15% of the crayons are less than 7 cm because\n\n100 - 99.7 = 0.3 (the percent of crayons either greater than 13 cm and less than 7 cm)\n\n0.3 / 2 = 0.15 (the percent of crayons less than 7 cm OR less than 7 cm).\n\nA 13 cm long crayon is super rare. In fact, there is only a 0.15% probability of getting a crayon 13 cm or longer.\n\nLet\u2019s now look at log ape\u2019s graph:\n\n&#x200B;\n\n[That's some pretty fucking solid eyeballing.](https://preview.redd.it/pbtv657s5u471.png?width=1600&format=png&auto=webp&s=164a9db39188d1f6d2aa413a6f478bd8720a0f83)\n\nFrom this graph there are only 2 values out of a total of 175 data points that would be considered \u201coutliers.\u201d I use outliers to mean values that do not fit the trend which is above the equation. 2 / 175 points is a mere 1.1% of the population. This amount is within reason for any regression type modeling.\n\nNote: this is extremely over simplification and a lot of things have been aped down for easier explanation. I won\u2019t be getting into that statistical calculation stuff because it\u2019s higher end so Imma stick to keeping it smooth brained\u2026. If I were on my work computer that has my fancy statistical analysis software, I would go balls to the wall. Sadly, I left that at work (where it belongs),\n\n**Data points usually deviate from a trend due to some form of bias.**\n\nI\u2019ve been looking into log ape\u2019s data and noticed that his variable \u201cd\u201d accounts for all days to include the weekend. 6/7 is day 250 and 6/4 is day 247.\n\n[6\\/7: d = 250](https://preview.redd.it/p03b5h9z5u471.png?width=1431&format=png&auto=webp&s=d312f4a748086d6d2faa8a54fd309fb5135f945f)\n\n[6\\/4: d = 247](https://preview.redd.it/elsgsgy36u471.png?width=1414&format=png&auto=webp&s=a58d87829011beda2cbb9b6d36655de92e9b6c5c)\n\nIf you were to only do business days, the dates would have a different associated d value. So, let\u2019s try to redo log ape\u2019s equation to only do trading days. The above graph would shift to look like this:\n\n&#x200B;\n\n[Well, fuck. There are lot more dips below the log equation.](https://preview.redd.it/gafj8u3b6u471.png?width=1600&format=png&auto=webp&s=0c80d45ccedd75e99d0f95ad88382c9ae31d1541)\n\nSince log ape\u2019s graph included the weekend, this compounded value would cause an influence on the resulting equation and would get more and more off due to more and more added weekends. Let\u2019s see what those intersections were that are essentially a bias causing a large deviation between the lowest share value and the log ape\u2019s equation:\n\n[This graph has more dates than I do. #4EvaAlone](https://preview.redd.it/coksvisatu471.png?width=2591&format=png&auto=webp&s=d3804613538928b42aa059540c112b28b0d6528f)\n\nInteresting\u2026 So from the graph, the most common cause for the lowest share price values to drop below the log ape\u2019s equation is when a new GME board member is announced. Followed by legislation, shares filing, and the holy FTD settlement theory.\n\nLong story short: When a trend deviates from it\u2019s normal trend, it is typically due to a bias. Calm your tits. We\u2019re still gucci. Log ape is fucking amazing for inspiring me and being my mathemagical muse.\n\n**TL;DR**\n\n**Hold the line.**\n\nSo big shout out to log ape for eye balling a pretty fucking solid equation. I\u2019m thoroughly impressed. I wish I had excel to do goal seek but I\u2019m not going to pay to buy MS office on my home computer.\n\nData sources:\n\n[Share Price Data](https://finance.yahoo.com/quote/GME/history?p=GME)\n\n[GME History](https://gmetimeline.com/)\n\nEdit 1: Updated the photos so they aren't for ants.\n\nEdit 2: Worded additonal biases into explanation.\n\nEdit 3: I am not saying exponential floor ape is wrong in any way. I am merely presenting a different method of viewing the data. Without exponential floor ape and his DD, none of this would be possible.\n\nEdit 4: pinging u/JTH1 for his point of view and reponse.\n\nEdit 5: The equation itself is not an exact measurement because the values in the original equation itself were guesstimated. Therefore, there will be inherit deltas due to inaccuracies. Yes, there are a bunch of other variables that can affect this trend but that would require some form of metrology that takes into account the human factors. I would argue this current trend line is capable of describing the majority of the model due to its high R\\^2 value. This isn't exact science nor a perfect model. It's hand wavy stats based around real world events.\n\nEdit 6: Updated crayon bell curve for better visual explanation.\n\nEdit 7:  u/WhatCanIMakeToday suggested I replace guy with ape. I took his advice.\n\nEdit 8: I figured I would make a [tweet](https://twitter.com/pwnwtfbbq/status/1403717359899090946) about this to share.\n\nEdit 9: Edited event graph to add all dates.\n\nEdit 10: Added more events within the dates. If you look at the trend and remove the \"outliers,\" you would see the more \"natural\" lowest share price. It would appear that these specific dates had a greater bias than the others.\n\nEdit 11: Exponential ape derived his equation looking at a definitive value. So, while it would appear that causing a shift would deviate from the original intent, it also doesn't since I'm looking at different types of data. The curve he presented fits the overall trend VERY well and we are viewing the data in different ways. He is looking at a constant value while I am looking into rates of change due to biases. In other words, he can give you a value, and I can give you the most influential reasons why it may change.\n\nEdit 12: debunk explanation",
    "title": "Technical analysis from an enginerd that has a hard on for statistical modeling and multivariate regression analysis.",
    "upvote_ratio": 0.98,
    "url": "https://www.reddit.com/r/Superstonk/comments/ny68t6/technical_analysis_from_an_enginerd_that_has_a/"
}